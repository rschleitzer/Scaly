package scaly 0.1.0

use scaly.memory.Page
use scaly.containers.Array
use scaly.containers.String

; Literal types
define StringLiteral(value: String)
define CharacterLiteral(value: String)
define FragmentLiteral(value: String)
define IntegerLiteral(value: String)
define BooleanLiteral(value: bool)
define FloatingPointLiteral(value: String)
define HexLiteral(value: String)

define Literal union (
    String: StringLiteral,
    Character: CharacterLiteral,
    Fragment: FragmentLiteral,
    Integer: IntegerLiteral,
    Boolean: BooleanLiteral,
    FloatingPoint: FloatingPointLiteral,
    Hex: HexLiteral
)

; Token types
define EmptyToken()
define InvalidToken()
define ColonToken()
define IdentifierToken(name: String)
define AttributeToken(name: String)
define PunctuationToken(sign: char)
define LiteralToken(value: Literal)

define Token union (
    Empty: EmptyToken,
    Invalid: InvalidToken,
    Colon: ColonToken,
    Identifier: IdentifierToken,
    Attribute: AttributeToken,
    Punctuation: PunctuationToken,
    Literal: LiteralToken
)

; Lexer state
define Lexer
(
    source: String
    current: size_t
    token: Token
    position: size_t
    previous_position: size_t
)
{
    init (source: String)
    {
        set this.source: source
        set current: 0
        set token: Token.Empty(EmptyToken())
        set position: 0
        set previous_position: 0
    }

    function is_at_end(this: Lexer) returns bool
        current >= source.length()

    procedure empty(this: Lexer)
        set token: Token.Empty(EmptyToken())

    procedure advance#(rp, this: Lexer)
    {
        set previous_position: position
        skip_whitespace(true)

        if is_at_end()
        {
            set token: Token.Empty(EmptyToken())
            return
        }

        let c source.get(current)

        ; Identifier or keyword
        if is_identifier_start(c)
        {
            set token: scan_identifier#()
            return
        }

        ; Attribute (@name)
        if c = "@" as char
        {
            set token: scan_attribute#()
            return
        }

        ; String literal
        if c = "\"" as char
        {
            set token: scan_string_literal#()
            return
        }

        ; Freeform identifier (single quotes)
        if c = "'" as char
        {
            set token: scan_freeform_identifier#()
            return
        }

        ; Numeric literal
        if is_digit(c)
        {
            set token: scan_numeric_literal#()
            return
        }

        ; Colon (special - used as separator)
        if c = ":" as char
        {
            set current: current + 1
            set position: current
            set token: Token.Colon(ColonToken())
            return
        }

        ; Single-line comment
        if c = ";" as char
        {
            if current + 1 < source.length() & source.get(current + 1) = "*" as char
            {
                handle_multi_line_comment()
                advance#()
                return
            }
            handle_single_line_comment()
            advance#()
            return
        }

        ; Punctuation and operators
        if is_punctuation(c)
        {
            set current: current + 1
            set position: current
            set token: Token.Punctuation(PunctuationToken(c))
            return
        }

        ; Operator characters
        if is_operator_char(c)
        {
            set token: scan_operator#()
            return
        }

        ; Fragment literal
        if c = "`" as char
        {
            set token: scan_fragment_literal#()
            return
        }

        ; Invalid character
        set current: current + 1
        set token: Token.Invalid(InvalidToken())
    }

    procedure skip_whitespace(this: Lexer, skip_linefeed: bool)
    {
        while current < source.length()
        {
            let c source.get(current)
            if (c = " " as char) | (c = "\t" as char) | (c = "\r" as char)
            {
                set current: current + 1
                continue
            }
            if skip_linefeed & (c = "\n" as char)
            {
                set current: current + 1
                continue
            }
            break
        }
        set position: current
    }

    procedure handle_single_line_comment(this: Lexer)
    {
        while current < source.length() & source.get(current) <> "\n" as char
            set current: current + 1
    }

    procedure handle_multi_line_comment(this: Lexer)
    {
        set current: current + 2  ; Skip ;*
        var nesting_level 1
        while current + 1 < source.length() & nesting_level > 0
        {
            if source.get(current) = ";" as char & source.get(current + 1) = "*" as char
            {
                set nesting_level: nesting_level + 1
                set current: current + 2
                continue
            }
            if source.get(current) = "*" as char & source.get(current + 1) = ";" as char
            {
                set nesting_level: nesting_level - 1
                set current: current + 2
                continue
            }
            set current: current + 1
        }
    }

    function scan_identifier#(rp, this: Lexer) returns Token
    {
        let start current
        while current < source.length() & is_identifier_char(source.get(current))
            set current: current + 1

        let name source.substring(rp, start, current - start)
        set position: current

        ; Check for boolean literals
        if name.equals("true")
            return Token.Literal(LiteralToken(Literal.Boolean(BooleanLiteral(true))))
        if name.equals("false")
            return Token.Literal(LiteralToken(Literal.Boolean(BooleanLiteral(false))))

        Token.Identifier(IdentifierToken(name))
    }

    function scan_attribute#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip @
        let start current
        while current < source.length() & is_identifier_char(source.get(current))
            set current: current + 1

        let name source.substring(rp, start, current - start)
        set position: current
        Token.Attribute(AttributeToken(name))
    }

    function scan_operator#(rp, this: Lexer) returns Token
    {
        let start current
        while current < source.length() & is_operator_char(source.get(current))
            set current: current + 1

        let name source.substring(rp, start, current - start)
        set position: current
        Token.Identifier(IdentifierToken(name))
    }

    function scan_string_literal#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip opening "
        let start current

        while current < source.length() & source.get(current) <> "\"" as char
        {
            if source.get(current) = "\\" as char
                set current: current + 1  ; Skip escape
            set current: current + 1
        }

        let value source.substring(rp, start, current - start)

        if current < source.length()
            set current: current + 1  ; Skip closing "

        set position: current
        Token.Literal(LiteralToken(Literal.String(StringLiteral(value))))
    }

    function scan_freeform_identifier#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip opening '
        let start current

        while current < source.length() & source.get(current) <> "'" as char
        {
            if source.get(current) = "\\" as char
                set current: current + 1  ; Skip escape
            set current: current + 1
        }

        let value source.substring(rp, start, current - start)

        if current < source.length()
            set current: current + 1  ; Skip closing '

        set position: current
        ; Return as identifier, not character literal
        Token.Identifier(IdentifierToken(value))
    }

    function scan_fragment_literal#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip opening `
        let start current

        while current < source.length() & source.get(current) <> "`" as char
            set current: current + 1

        let value source.substring(rp, start, current - start)

        if current < source.length()
            set current: current + 1  ; Skip closing `

        set position: current
        Token.Literal(LiteralToken(Literal.Fragment(FragmentLiteral(value))))
    }

    function scan_numeric_literal#(rp, this: Lexer) returns Token
    {
        let start current

        ; Check for hex literal (0x...)
        if source.get(current) = "0" as char & current + 1 < source.length()
        {
            let next source.get(current + 1)
            if next = "x" as char | next = "X" as char
            {
                set current: current + 2
                while current < source.length() & is_hex_digit(source.get(current))
                    set current: current + 1
                let value source.substring(rp, start + 2, current - start - 2)
                set position: current
                return Token.Literal(LiteralToken(Literal.Hex(HexLiteral(value))))
            }
        }

        ; Integer part
        while current < source.length() & is_digit(source.get(current))
            set current: current + 1

        ; Check for decimal point
        if current < source.length() & source.get(current) = "." as char
        {
            set current: current + 1
            while current < source.length() & is_digit(source.get(current))
                set current: current + 1

            ; Check for exponent
            if current < source.length()
            {
                let exp_char source.get(current)
                let e_lower: char = "e"
                if exp_char = e_lower | exp_char = "E" as char
                {
                    set current: current + 1
                    ; Optional sign
                    if current < source.length()
                    {
                        let sign_char source.get(current)
                        if sign_char = "+" as char | sign_char = "-" as char
                            set current: current + 1
                    }
                    while current < source.length() & is_digit(source.get(current))
                        set current: current + 1
                }
            }

            let value source.substring(rp, start, current - start)
            set position: current
            return Token.Literal(LiteralToken(Literal.FloatingPoint(FloatingPointLiteral(value))))
        }

        let value source.substring(rp, start, current - start)
        set position: current
        Token.Literal(LiteralToken(Literal.Integer(IntegerLiteral(value))))
    }

    ; Parser helper methods
    function parse_keyword#(rp, this: Lexer, keyword: String) returns bool
    {
        choose token
            when id: Identifier
            {
                if id.name.equals(keyword)
                {
                    advance#()
                    return true
                }
            }
        false
    }

    function parse_identifier#(rp, this: Lexer) returns String
    {
        choose token
            when id: Identifier
            {
                let name id.name
                advance#()
                return name
            }
        String()
    }

    function parse_punctuation#(rp, this: Lexer, c: char) returns bool
    {
        choose token
            when p: Punctuation
            {
                if p.sign = c
                {
                    advance#()
                    return true
                }
            }
        false
    }

    function parse_colon#(rp, this: Lexer) returns bool
    {
        choose token
            when c: Colon
            {
                advance#()
                return true
            }
        false
    }

    function parse_attribute#(rp, this: Lexer) returns String
    {
        choose token
            when a: Attribute
            {
                let name a.name
                advance#()
                return name
            }
        String()
    }
}

; Character classification helpers
function is_identifier_start(c: char) returns bool
    (c >= "a" as char & c <= "z" as char) | (c >= "A" as char & c <= "Z" as char) | c = "_" as char

function is_identifier_char(c: char) returns bool
    is_identifier_start(c) | is_digit(c)

function is_digit(c: char) returns bool
    c >= "0" as char & c <= "9" as char

function is_hex_digit(c: char) returns bool
    is_digit(c) | (c >= "a" as char & c <= "f" as char) | (c >= "A" as char & c <= "F" as char)

function is_operator_char(c: char) returns bool
    c = "+" as char | c = "-" as char | c = "*" as char | c = "/" as char | c = "=" as char | c = "<" as char | c = ">" as char | c = "&" as char | c = "|" as char | c = "~" as char | c = "^" as char | c = "%" as char

function is_punctuation(c: char) returns bool
    c = "(" as char | c = ")" as char | c = "[" as char | c = "]" as char | c = "{" as char | c = "}" as char | c = "," as char | c = "." as char

; Test helper classification functions
function test_helpers() returns int
{
    ; Test is_identifier_start
    if ~is_identifier_start("a" as char)
        return -1
    if ~is_identifier_start("Z" as char)
        return -2
    if ~is_identifier_start("_" as char)
        return -3
    if is_identifier_start("0" as char)
        return -4
    if is_identifier_start(" " as char)
        return -5

    ; Test is_digit
    if ~is_digit("0" as char)
        return -6
    if ~is_digit("9" as char)
        return -7
    if is_digit("a" as char)
        return -8

    ; Test is_hex_digit
    if ~is_hex_digit("0" as char)
        return -9
    if ~is_hex_digit("a" as char)
        return -10
    if ~is_hex_digit("F" as char)
        return -11
    if is_hex_digit("g" as char)
        return -12

    ; Test is_punctuation
    if ~is_punctuation("(" as char)
        return -13
    if ~is_punctuation(")" as char)
        return -14
    if is_punctuation(":" as char)
        return -15

    ; Test is_operator_char
    if ~is_operator_char("+" as char)
        return -16
    if ~is_operator_char("-" as char)
        return -17
    if is_operator_char("a" as char)
        return -18

    0
}

; Test string creation and basic operations
function test_string_basics() returns int
{
    var rp Page.allocate_page()
    var s String^rp("hello")

    ; Check length using function call syntax (workaround for method call bug)
    let len get_length(s)
    if len <> 5
    {
        free(rp as pointer[void])
        return -1
    }

    ; Check individual characters
    if get(s, 0) <> "h" as char
    {
        free(rp as pointer[void])
        return -2
    }

    if get(s, 4) <> "o" as char
    {
        free(rp as pointer[void])
        return -3
    }

    free(rp as pointer[void])
    0
}

; Test lexer creation
function test_lexer_creation() returns int
{
    var rp Page.allocate_page()
    var lexer Lexer(String^rp("hello"))

    ; Check initial state
    if lexer.current <> 0
    {
        free(rp as pointer[void])
        return -1
    }

    ; Check initial token is Empty
    choose lexer.token
        when e: Empty
        {
            free(rp as pointer[void])
            return 0
        }
        else
        {
            free(rp as pointer[void])
            return -2
        }
}

; Main test function
function test() returns int
{
    var result test_helpers()
    if result <> 0
        return result - 100

    set result: test_string_basics()
    if result <> 0
        return result - 200

    set result: test_lexer_creation()
    if result <> 0
        return result - 300

    0
}

