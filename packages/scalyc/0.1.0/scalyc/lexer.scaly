package scaly 0.1.0

use scaly.memory.Page
use scaly.containers.Array
use scaly.containers.String

; Character constants (char literals use double-quote + type annotation)
let CHAR_AT: char = "@"
let CHAR_DQUOTE: char = "\""
let CHAR_SQUOTE: char = "'"
let CHAR_COLON: char = ":"
let CHAR_SEMI: char = ";"
let CHAR_STAR: char = "*"
let CHAR_BACKTICK: char = "`"
let CHAR_BACKSLASH: char = "\\"
let CHAR_SPACE: char = " "
let CHAR_TAB: char = "\t"
let CHAR_CR: char = "\r"
let CHAR_LF: char = "\n"
let CHAR_DOT: char = "."
let CHAR_PLUS: char = "+"
let CHAR_MINUS: char = "-"
let CHAR_SLASH: char = "/"
let CHAR_EQ: char = "="
let CHAR_LT: char = "<"
let CHAR_GT: char = ">"
let CHAR_AMP: char = "&"
let CHAR_PIPE: char = "|"
let CHAR_TILDE: char = "~"
let CHAR_CARET: char = "^"
let CHAR_PERCENT: char = "%"
let CHAR_LPAREN: char = "("
let CHAR_RPAREN: char = ")"
let CHAR_LBRACKET: char = "["
let CHAR_RBRACKET: char = "]"
let CHAR_LBRACE: char = "{"
let CHAR_RBRACE: char = "}"
let CHAR_COMMA: char = ","
let CHAR_UNDERSCORE: char = "_"
let CHAR_0: char = "0"
let CHAR_9: char = "9"
let CHAR_a: char = "a"
let CHAR_f: char = "f"
let CHAR_g: char = "g"
let CHAR_h: char = "h"
let CHAR_n: char = "n"
let CHAR_o: char = "o"
let CHAR_r: char = "r"
let CHAR_t: char = "t"
let CHAR_x: char = "x"
let CHAR_z: char = "z"
let CHAR_A: char = "A"
let CHAR_E: char = "E"
let CHAR_F: char = "F"
let CHAR_X: char = "X"
let CHAR_Z: char = "Z"

; Literal types
define StringLiteral(value: String)
define CharacterLiteral(value: String)
define FragmentLiteral(value: String)
define IntegerLiteral(value: String)
define BooleanLiteral(value: bool)
define FloatingPointLiteral(value: String)
define HexLiteral(value: String)

define Literal union (
    String: StringLiteral,
    Character: CharacterLiteral,
    Fragment: FragmentLiteral,
    Integer: IntegerLiteral,
    Boolean: BooleanLiteral,
    FloatingPoint: FloatingPointLiteral,
    Hex: HexLiteral
)

; Token types
define EmptyToken()
define InvalidToken()
define ColonToken()
define IdentifierToken(name: String)
define AttributeToken(name: String)
define PunctuationToken(sign: char)
define LiteralToken(value: Literal)

define Token union (
    Empty: EmptyToken,
    Invalid: InvalidToken,
    Colon: ColonToken,
    Identifier: IdentifierToken,
    Attribute: AttributeToken,
    Punctuation: PunctuationToken,
    Literal: LiteralToken
)

; Lexer state
define Lexer
(
    source: String
    current: size_t
    token: Token
    position: size_t
    previous_position: size_t
)
{
    init (source: String)
    {
        set this.source: source
        set current: 0
        set token: Token.Empty(EmptyToken())
        set position: 0
        set previous_position: 0
    }

    function is_at_end(this: Lexer) returns bool
        current >= source.length()

    procedure advance#(rp, this: Lexer)
    {
        set previous_position: position
        skip_whitespace(true)

        if is_at_end()
        {
            set token: Token.Empty(EmptyToken())
            return
        }

        let c source.get(current)

        ; Identifier or keyword
        if is_identifier_start(c)
        {
            set token: scan_identifier#()
            return
        }

        ; Attribute (@name)
        if c = CHAR_AT
        {
            set token: scan_attribute#()
            return
        }

        ; String literal
        if c = CHAR_DQUOTE
        {
            set token: scan_string_literal#()
            return
        }

        ; Freeform identifier (single quotes)
        if c = CHAR_SQUOTE
        {
            set token: scan_freeform_identifier#()
            return
        }

        ; Numeric literal
        if is_digit(c)
        {
            set token: scan_numeric_literal#()
            return
        }

        ; Colon (special - used as separator)
        if c = CHAR_COLON
        {
            set current: current + 1
            set position: current
            set token: Token.Colon(ColonToken())
            return
        }

        ; Single-line comment
        if c = CHAR_SEMI
        {
            if current + 1 < source.length() & source.get(current + 1) = CHAR_STAR
            {
                handle_multi_line_comment()
                advance#()
                return
            }
            handle_single_line_comment()
            advance#()
            return
        }

        ; Punctuation and operators
        if is_punctuation(c)
        {
            set current: current + 1
            set position: current
            set token: Token.Punctuation(PunctuationToken(c))
            return
        }

        ; Operator characters
        if is_operator_char(c)
        {
            set token: scan_operator#()
            return
        }

        ; Fragment literal
        if c = CHAR_BACKTICK
        {
            set token: scan_fragment_literal#()
            return
        }

        ; Invalid character
        set current: current + 1
        set token: Token.Invalid(InvalidToken())
    }

    procedure skip_whitespace(this: Lexer, skip_linefeed: bool)
    {
        while current < source.length()
        {
            let c source.get(current)
            if (c = CHAR_SPACE) | (c = CHAR_TAB) | (c = CHAR_CR)
            {
                set current: current + 1
                continue
            }
            if skip_linefeed & (c = CHAR_LF)
            {
                set current: current + 1
                continue
            }
            break
        }
        set position: current
    }

    procedure handle_single_line_comment(this: Lexer)
    {
        while current < source.length() & source.get(current) <> CHAR_LF
            set current: current + 1
    }

    procedure handle_multi_line_comment(this: Lexer)
    {
        set current: current + 2  ; Skip ;*
        var nesting_level 1
        while current + 1 < source.length() & nesting_level > 0
        {
            if source.get(current) = CHAR_SEMI & source.get(current + 1) = CHAR_STAR
            {
                set nesting_level: nesting_level + 1
                set current: current + 2
                continue
            }
            if source.get(current) = CHAR_STAR & source.get(current + 1) = CHAR_SEMI
            {
                set nesting_level: nesting_level - 1
                set current: current + 2
                continue
            }
            set current: current + 1
        }
    }

    function scan_identifier#(rp, this: Lexer) returns Token
    {
        let start current
        while current < source.length() & is_identifier_char(source.get(current))
            set current: current + 1

        let name source.substring(rp, start, current - start)
        set position: current

        ; Check for boolean literals
        if name.equals("true")
            return Token.Literal(LiteralToken(Literal.Boolean(BooleanLiteral(true))))
        if name.equals("false")
            return Token.Literal(LiteralToken(Literal.Boolean(BooleanLiteral(false))))

        Token.Identifier(IdentifierToken(name))
    }

    function scan_attribute#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip @
        let start current
        while current < source.length() & is_identifier_char(source.get(current))
            set current: current + 1

        let name source.substring(rp, start, current - start)
        set position: current
        Token.Attribute(AttributeToken(name))
    }

    function scan_operator#(rp, this: Lexer) returns Token
    {
        let start current
        while current < source.length() & is_operator_char(source.get(current))
            set current: current + 1

        let name source.substring(rp, start, current - start)
        set position: current
        Token.Identifier(IdentifierToken(name))
    }

    function scan_string_literal#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip opening "
        let start current

        while current < source.length() & source.get(current) <> CHAR_DQUOTE
        {
            if source.get(current) = CHAR_BACKSLASH
                set current: current + 1  ; Skip escape
            set current: current + 1
        }

        let value source.substring(rp, start, current - start)

        if current < source.length()
            set current: current + 1  ; Skip closing "

        set position: current
        Token.Literal(LiteralToken(Literal.String(StringLiteral(value))))
    }

    function scan_freeform_identifier#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip opening '
        let start current

        while current < source.length() & source.get(current) <> CHAR_SQUOTE
        {
            if source.get(current) = CHAR_BACKSLASH
                set current: current + 1  ; Skip escape
            set current: current + 1
        }

        let value source.substring(rp, start, current - start)

        if current < source.length()
            set current: current + 1  ; Skip closing '

        set position: current
        ; Return as identifier, not character literal
        Token.Identifier(IdentifierToken(value))
    }

    function scan_fragment_literal#(rp, this: Lexer) returns Token
    {
        set current: current + 1  ; Skip opening `
        let start current

        while current < source.length() & source.get(current) <> CHAR_BACKTICK
            set current: current + 1

        let value source.substring(rp, start, current - start)

        if current < source.length()
            set current: current + 1  ; Skip closing `

        set position: current
        Token.Literal(LiteralToken(Literal.Fragment(FragmentLiteral(value))))
    }

    function scan_numeric_literal#(rp, this: Lexer) returns Token
    {
        let start current

        ; Check for hex literal (0x...)
        if source.get(current) = CHAR_0 & current + 1 < source.length()
        {
            let next source.get(current + 1)
            if next = CHAR_x | next = CHAR_X
            {
                set current: current + 2
                while current < source.length() & is_hex_digit(source.get(current))
                    set current: current + 1
                let value source.substring(rp, start + 2, current - start - 2)
                set position: current
                return Token.Literal(LiteralToken(Literal.Hex(HexLiteral(value))))
            }
        }

        ; Integer part
        while current < source.length() & is_digit(source.get(current))
            set current: current + 1

        ; Check for decimal point
        if current < source.length() & source.get(current) = CHAR_DOT
        {
            set current: current + 1
            while current < source.length() & is_digit(source.get(current))
                set current: current + 1

            ; Check for exponent
            if current < source.length()
            {
                let exp_char source.get(current)
                let e_lower: char = "e"
                if exp_char = e_lower | exp_char = CHAR_E
                {
                    set current: current + 1
                    ; Optional sign
                    if current < source.length()
                    {
                        let sign_char source.get(current)
                        if sign_char = CHAR_PLUS | sign_char = CHAR_MINUS
                            set current: current + 1
                    }
                    while current < source.length() & is_digit(source.get(current))
                        set current: current + 1
                }
            }

            let value source.substring(rp, start, current - start)
            set position: current
            return Token.Literal(LiteralToken(Literal.FloatingPoint(FloatingPointLiteral(value))))
        }

        let value source.substring(rp, start, current - start)
        set position: current
        Token.Literal(LiteralToken(Literal.Integer(IntegerLiteral(value))))
    }

    ; Parser helper methods
    function parse_keyword#(rp, this: Lexer, keyword: String) returns bool
    {
        choose token
            when id: Identifier
            {
                if id.name.equals(keyword)
                {
                    advance#()
                    return true
                }
            }
        false
    }

    function parse_identifier#(rp, this: Lexer) returns String
    {
        choose token
            when id: Identifier
            {
                let name id.name
                advance#()
                return name
            }
        String()
    }

    function parse_punctuation#(rp, this: Lexer, c: char) returns bool
    {
        choose token
            when p: Punctuation
            {
                if p.sign = c
                {
                    advance#()
                    return true
                }
            }
        false
    }

    function parse_colon#(rp, this: Lexer) returns bool
    {
        choose token
            when c: Colon
            {
                advance#()
                return true
            }
        false
    }
}

; Character classification helpers
function is_identifier_start(c: char) returns bool
    (c >= CHAR_a & c <= CHAR_z) | (c >= CHAR_A & c <= CHAR_Z) | c = CHAR_UNDERSCORE

function is_identifier_char(c: char) returns bool
    is_identifier_start(c) | is_digit(c)

function is_digit(c: char) returns bool
    c >= CHAR_0 & c <= CHAR_9

function is_hex_digit(c: char) returns bool
    is_digit(c) | (c >= CHAR_a & c <= CHAR_f) | (c >= CHAR_A & c <= CHAR_F)

function is_operator_char(c: char) returns bool
    c = CHAR_PLUS | c = CHAR_MINUS | c = CHAR_STAR | c = CHAR_SLASH | c = CHAR_EQ | c = CHAR_LT | c = CHAR_GT | c = CHAR_AMP | c = CHAR_PIPE | c = CHAR_TILDE | c = CHAR_CARET | c = CHAR_PERCENT

function is_punctuation(c: char) returns bool
    c = CHAR_LPAREN | c = CHAR_RPAREN | c = CHAR_LBRACKET | c = CHAR_RBRACKET | c = CHAR_LBRACE | c = CHAR_RBRACE | c = CHAR_COMMA | c = CHAR_DOT

; Test helper classification functions
function test_helpers() returns int
{
    ; Test is_identifier_start
    if ~is_identifier_start(CHAR_a)
        return -1
    if ~is_identifier_start(CHAR_Z)
        return -2
    if ~is_identifier_start(CHAR_UNDERSCORE)
        return -3
    if is_identifier_start(CHAR_0)
        return -4
    if is_identifier_start(CHAR_SPACE)
        return -5

    ; Test is_digit
    if ~is_digit(CHAR_0)
        return -6
    if ~is_digit(CHAR_9)
        return -7
    if is_digit(CHAR_a)
        return -8

    ; Test is_hex_digit
    if ~is_hex_digit(CHAR_0)
        return -9
    if ~is_hex_digit(CHAR_a)
        return -10
    if ~is_hex_digit(CHAR_F)
        return -11
    if is_hex_digit(CHAR_g)
        return -12

    ; Test is_punctuation
    if ~is_punctuation(CHAR_LPAREN)
        return -13
    if ~is_punctuation(CHAR_RPAREN)
        return -14
    if is_punctuation(CHAR_COLON)
        return -15

    ; Test is_operator_char
    if ~is_operator_char(CHAR_PLUS)
        return -16
    if ~is_operator_char(CHAR_MINUS)
        return -17
    if is_operator_char(CHAR_a)
        return -18

    0
}

; Test string creation and basic operations
function test_string_basics() returns int
{
    var rp Page.allocate_page()
    var s String^rp("hello")

    ; Check length using function call syntax (workaround for method call bug)
    let len get_length(s)
    if len <> 5
    {
        free(rp as pointer[void])
        return -1
    }

    ; Check individual characters
    if get(s, 0) <> CHAR_h
    {
        free(rp as pointer[void])
        return -2
    }

    if get(s, 4) <> CHAR_o
    {
        free(rp as pointer[void])
        return -3
    }

    free(rp as pointer[void])
    0
}

; Test lexer creation
function test_lexer_creation() returns int
{
    var rp Page.allocate_page()
    var lexer Lexer(String^rp("hello"))

    ; Check initial state
    if lexer.current <> 0
    {
        free(rp as pointer[void])
        return -1
    }

    ; Check initial token is Empty
    choose lexer.token
        when e: Empty
        {
            free(rp as pointer[void])
            return 0
        }
        else
        {
            free(rp as pointer[void])
            return -2
        }
}

; Main test function
function test() returns int
{
    var result test_helpers()
    if result <> 0
        return result - 100

    set result: test_string_basics()
    if result <> 0
        return result - 200

    set result: test_lexer_creation()
    if result <> 0
        return result - 300

    0
}

